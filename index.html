<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.5.0" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.5.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.5.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.5.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.5.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.5.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Stay hungry, stay foolish.">
<meta property="og:type" content="website">
<meta property="og:title" content="Zekang Li&#39;s Blog">
<meta property="og:url" content="https://lizekang.github.io/index.html">
<meta property="og:site_name" content="Zekang Li&#39;s Blog">
<meta property="og:description" content="Stay hungry, stay foolish.">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Zekang Li&#39;s Blog">
<meta name="twitter:description" content="Stay hungry, stay foolish.">



  <link rel="alternate" href="/atom.xml" title="Zekang Li's Blog" type="application/atom+xml">




  <link rel="canonical" href="https://lizekang.github.io/">



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Zekang Li's Blog</title>
  











  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Zekang Li's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-sitemap">
    <a href="/sitemap.xml" rel="section">
      <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br>站点地图</a>
  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://lizekang.github.io/2018/11/19/1/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zekang Li">
      <meta itemprop="description" content="Stay hungry, stay foolish.">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zekang Li's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/19/1/" itemprop="url">
                  《Visual Question Answering with Memory-Augmented Networks》阅读笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-11-19 14:53:26 / 修改时间：15:36:25" itemprop="dateCreated datePublished" datetime="2018-11-19T14:53:26+08:00">2018-11-19</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/CV/" itemprop="url" rel="index"><span itemprop="name">CV</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="《Visual-Question-Answering-with-Memory-Augmented-Networks》"><a href="#《Visual-Question-Answering-with-Memory-Augmented-Networks》" class="headerlink" title="《Visual Question Answering with Memory-Augmented Networks》"></a>《Visual Question Answering with Memory-Augmented Networks》</h2><blockquote>
<p>前段时间比赛所需，读了一些关于VQA（Visual Question and Answering）的论文，这篇文章是CVPR2018的一篇文章，亮点在于使用了Memory-Augmented Networks来增加模型对低频答案的识别率。</p>
</blockquote>
<ol>
<li><p><strong>Abstract</strong><br> 在传统的VQA问题中，我们采用梯度下降来更新模型，这种更新方式会使模型预测更倾向于高频答案，本篇论文采用Memory Augmented Network的方法来增加对低频答案的识别率。</p>
</li>
<li><p><strong>论文整体框架</strong><br><img src="https://note.youdao.com/yws/res/554/636430EE8FCB47B6A9B00A78D8FF3B4E" alt="image"><br>主要分为三个部分：图片与问题特征提取，图片和问题特征融合（Co-attention），记忆增强网络。</p>
<ol>
<li>图片与问题特征提取<br> 这边用的方法比较传统。对问题，通过双向LSTM去提取特征；对于图片，使用VGG等预训练模型提取特征。</li>
<li>图片与问题特征融合（Co-Attention）<br> 这里借鉴了2016年NIPS一篇论文<a href="https://arxiv.org/pdf/1606.00061.pdf" target="_blank" rel="noopener">《Hierarchical Question-Image Co-Attention for Visual Question Answering》</a><br> <img src="https://note.youdao.com/yws/res/597/4DD67B95E9884D2DAA73A724A9591938" alt="image"><br> 方法比较简单，直接上公式了<br> <img src="https://note.youdao.com/yws/res/607/C34613DA52FA4D3FB51C4807DD62C6C9" alt="image"><br> <img src="https://note.youdao.com/yws/res/611/558441BEC8B84479BAD54ECD1E557E58" alt="image"><br> <img src="https://note.youdao.com/yws/res/613/37F4C82258974B848743F4CA5F57ECA3" alt="image"></li>
<li><p>记忆增强网络<br> 这个模块算是这篇文章的亮点吧，在之江杯视频问答中我复现了这个模块，但是效果不是很好:(<br> 在这个模块中用了一个LSTM网络做Controller，以及一个External Memory $M$<br> 在训练过程中，对于所有训练数据${x_{t}, y_{t}}; t= 1…T$,把$x_{t}$丢进controller里面去得到一个query $h_{t}$<br> $$ h_{t} = LSTM(x_{t}, h_{t-1}) $$<br> 之后通过这个query去从Memory中读取信息<br> $$ D(h_{t}, M_{t}(i)) = \frac{h_{t}\cdot M_{t}(i)}{|h_{t}||M_{t}(i)|} $$<br> $$ w^{r}<em>{t} = softmax(D(h</em>{t}, M_{t}(i))) $$<br> $$ r_{t} = \sum_{i} w^{r}<em>{t}(i)M</em>{i} $$</p>
<blockquote>
<p>we would like the writer to strike a balance between writing new information to rarely used location and writing to recently used location</p>
</blockquote>
<p> 这里，作者提出了一种平衡低频memory和高频memory的读写的方法。<br> $$ w^{u}<em>{t} = \gamma w^{u}</em>{t-1} + w_{t}^{r} + w_{t}^{w} $$<br> $$ w^{w}<em>{t} = (1 - \sigma(\alpha))w^{r}</em>{t-1} + (1-\sigma(\alpha))1(w_{t-1}^{u}\leqslant m(w_{t-1}^{u}, n)) $$<br> $$ M_{t}^{i} = M_{t-1}^{i} + w_{t}^{w}*h_{t} $$<br> 注意：这边的$\alpha$是learnable的，来控制低频和高频的使用频率。<br> 最后把$r_{t}$ 和 $h_{t}$拼接起来丢到分类器里面。</p>
</li>
</ol>
</li>
<li>Summary</li>
</ol>
<ul>
<li>这篇论文其实看懂了非常好理解，理论上可以一定程度上解决数据分布不平衡导致模型更倾向于预测高频答案的问题。但是这个模型我一直没有调好，不清楚是因为什么问题。</li>
<li>最近Memory Network很火，主要是因为它模拟人的记忆，使用更少的样本就可以达到相同的效果，也就是Meta-learning的思想，什么One-shot， Zero-shot之类的。</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://lizekang.github.io/2018/11/19/1/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zekang Li">
      <meta itemprop="description" content="Stay hungry, stay foolish.">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zekang Li's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/19/1/" itemprop="url">
                  《Tag Disentangled Generative Adversarial Networks for Object Image Re-rendering》阅读笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-11-19 14:48:00 / 修改时间：15:36:44" itemprop="dateCreated datePublished" datetime="2018-11-19T14:48:00+08:00">2018-11-19</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/CV/" itemprop="url" rel="index"><span itemprop="name">CV</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="《Tag-Disentangled-Generative-Adversarial-Networks-for-Object-Image-Re-rendering》"><a href="#《Tag-Disentangled-Generative-Adversarial-Networks-for-Object-Image-Re-rendering》" class="headerlink" title="《Tag Disentangled Generative Adversarial Networks for Object Image Re-rendering》"></a>《Tag Disentangled Generative Adversarial Networks for Object Image Re-rendering》</h1><blockquote>
<p>最近在研究多视角数据增强的方法，读到了这一篇，感觉思想很重要 </p>
</blockquote>
<blockquote>
<p>这篇文章是IJCAI2017的最佳学生论文，简称TD-GAN，用于从单个输入图像中提取可分解的特征，并通过调整所学特征来重新渲染图像。</p>
</blockquote>
<blockquote>
<p>附上链接：<a href="https://www.ijcai.org/proceedings/2017/0404.pdf" target="_blank" rel="noopener">https://www.ijcai.org/proceedings/2017/0404.pdf</a> </p>
</blockquote>
<blockquote>
<p>目前我复现了一部分，还没写完，<a href="https://github.com/lizekang/TD-GAN" target="_blank" rel="noopener">https://github.com/lizekang/TD-GAN</a></p>
</blockquote>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a><strong>Abstract</strong></h2><p>本文提出了一种全新的神经网络框架，标签分解生成对抗网络(Tag Disentangled Generative Adversarial Networks, TDGAN)，用于进行目标图像的再次渲染(Re-rendering)。给定目标图像作为输入，该网络(TDGAN)即可根据指定要求修改图像内容，并生成符合描述的图像。例如，改变输入图像的观察角度，光照条件，人脸表情等等。和以往工作不同，通过利用图像与其标签的对应关系，即标签是图像分解表征(disentangled representations, DR)的Embedding，我们训练分解网络以提取输入图像的分解表征(DR)。生成网络根据这些表征以及新的标签重新渲染图像。</p>
<h2 id="Network-Architecture"><a href="#Network-Architecture" class="headerlink" title="Network Architecture"></a><strong>Network Architecture</strong></h2><p><img src="https://bbs.dian.org.cn/assets/uploads/files/1541148671827-ffdb82c2-f8d6-487a-86cf-10f6cf3c490c-image-resized.png" alt="0_1541148666873_ffdb82c2-f8d6-487a-86cf-10f6cf3c490c-image.png"> </p>
<p>文章中使用了四个网络，a disentangling network, a generative network, a tag mapping net, and a discriminative network。</p>
<ul>
<li><p><strong>Disentangling Network</strong></p>
<p>  用来分解图片特征的网络，将图片的表征分解成几个独立的domain，比如光照，表情，viewpoint等。</p>
</li>
<li><p><strong>Tag Mapping Net</strong></p>
<p>  用来将不同Domain的标签mapping到Disentangling Network分解出来的对应domain上，之后就可以使用Tag Mapping Net生成的特征来替换掉Disentangling Network产生的特征了。</p>
</li>
<li><p><strong>Generative Network</strong></p>
<p>  生成器，根据重组后的特征生成图像</p>
</li>
<li><p><strong>Discriminative Network</strong></p>
<p>  辨别器，辨别生成的图像真/假</p>
</li>
</ul>
<p>看完网络结构感觉这篇文章其实思路很简单，就是替换feature罢了，但是我觉得真正困难的地方是这样一个比较复杂的网络该怎么去训练。果不其然，作者用大篇幅介绍了如何训练以及参数设置，可以说是很良心了。</p>
<h2 id="网络训练策略"><a href="#网络训练策略" class="headerlink" title="网络训练策略"></a><strong>网络训练策略</strong></h2><p>直接上公式了，对应着图看着公式基本能明白是干什么的（带*的代表冻结该网络）</p>
<p><img src="https://bbs.dian.org.cn/assets/uploads/files/1541149687254-f4de0d54-b59b-47c2-8f29-b6a274d170b2-image.png" alt="0_1541149682977_f4de0d54-b59b-47c2-8f29-b6a274d170b2-image.png"> </p>
<p><img src="https://bbs.dian.org.cn/assets/uploads/files/1541149697379-231aa761-1d37-4bab-81fc-72bcf7a553d7-image.png" alt="0_1541149693295_231aa761-1d37-4bab-81fc-72bcf7a553d7-image.png"> </p>
<p><img src="https://bbs.dian.org.cn/assets/uploads/files/1541149707361-dd76a590-633c-43bd-956b-e942b30e0e5a-image.png" alt="0_1541149703259_dd76a590-633c-43bd-956b-e942b30e0e5a-image.png"> </p>
<p><img src="https://bbs.dian.org.cn/assets/uploads/files/1541149716175-4894adff-1e9b-4f2d-a7c3-67c8913ba5a2-image.png" alt="0_1541149712084_4894adff-1e9b-4f2d-a7c3-67c8913ba5a2-image.png"> </p>
<p><img src="https://bbs.dian.org.cn/assets/uploads/files/1541149737248-5050c717-05b0-4034-8859-5f32aab07d4d-image.png" alt="0_1541149733132_5050c717-05b0-4034-8859-5f32aab07d4d-image.png"> </p>
<p><img src="https://bbs.dian.org.cn/assets/uploads/files/1541149745460-0f3c071d-e9cf-49f4-8c40-0b59ad8da7ef-image.png" alt="0_1541149741368_0f3c071d-e9cf-49f4-8c40-0b59ad8da7ef-image.png"> </p>
<p><img src="https://bbs.dian.org.cn/assets/uploads/files/1541149754886-00ac8a97-4843-4ece-80fd-0dc3e84f9f9e-image.png" alt="0_1541149750800_00ac8a97-4843-4ece-80fd-0dc3e84f9f9e-image.png"> </p>
<p><img src="https://bbs.dian.org.cn/assets/uploads/files/1541149762921-706d4983-ec97-48e6-8696-f4f0dc1f67b5-image.png" alt="0_1541149758827_706d4983-ec97-48e6-8696-f4f0dc1f67b5-image.png"> </p>
<h2 id="网络参数设置"><a href="#网络参数设置" class="headerlink" title="网络参数设置"></a><strong>网络参数设置</strong></h2><p><img src="https://bbs.dian.org.cn/assets/uploads/files/1541149883166-db41c557-2d34-4785-998d-542aa2ce737c-image.png" alt="0_1541149878814_db41c557-2d34-4785-998d-542aa2ce737c-image.png"> </p>
<p><img src="https://bbs.dian.org.cn/assets/uploads/files/1541149892729-14ba550e-772a-445c-8ceb-42dae0d8ff58-image.png" alt="0_1541149888581_14ba550e-772a-445c-8ceb-42dae0d8ff58-image.png"> </p>
<h2 id="惊艳的实验结果"><a href="#惊艳的实验结果" class="headerlink" title="惊艳的实验结果"></a><strong>惊艳的实验结果</strong></h2><p><img src="https://bbs.dian.org.cn/assets/uploads/files/1541149948275-8965ff18-c92b-4159-9be3-0c4ea99a3e43-image.png" alt="0_1541149944111_8965ff18-c92b-4159-9be3-0c4ea99a3e43-image.png"> </p>
<p><img src="https://bbs.dian.org.cn/assets/uploads/files/1541149958343-d5d2357b-9f08-48a8-9c50-b1f27cfd6626-image.png" alt="0_1541149954104_d5d2357b-9f08-48a8-9c50-b1f27cfd6626-image.png"> </p>
<p><img src="https://bbs.dian.org.cn/assets/uploads/files/1541149977353-7e7fc577-811b-49d5-bc14-14ac3fc81533-image.png" alt="0_1541149973197_7e7fc577-811b-49d5-bc14-14ac3fc81533-image.png"></p>
<h2 id="一点思考"><a href="#一点思考" class="headerlink" title="一点思考"></a><strong>一点思考</strong></h2><p>转自：<a href="http://www.sohu.com/a/257772655_473283" target="_blank" rel="noopener">http://www.sohu.com/a/257772655_473283</a></p>
<p>多视角学习：面向决策策略的“盲人摸象”</p>
<p>大家都知道盲人摸象的故事，实际上我们做决策的时候，跟盲人是一样的，因为我们所获取到的信息也是不完整的。那么我们在做觉得时候，也就是根据已有的信息作出的最优策略。因此，对于同样的事情，每一个人所作出的决定可能也不相同。</p>
<p>多视角学习对于现今的智能系统非常重要，这是因为智能系统中都安装了大量的传感器，比如，现在的无人车安装了激光雷达、毫米波雷达、摄像机、IMU等等。每个传感器都只能够感知环境中的部分信息，那么我们就需要把不同的传感的信息融合起来，帮助我们做最后的决策。</p>
<p>假设存在一个oracle space，那么每个传感器就可以被建模成对oracle space的一个线性或者非线形投影。如果我们有大量的传感器，那么我们就能够获取大量的投影信息。我们可以证明，如果说我们有足够多的不同的投影信息，我们就能够以非常高的概率去重构这个oracle space。有了这个oracle space，我们就可以有效的做决策了。</p>
<p>请大家看一下最左边的这张图像。你第一眼看到了什么？大多说人一定会说是船。然后你还会注意到船上有人。对不对？这个现象提示我们，这样的顺序信息对于我们进行多标签学习会非常有帮助。通过增强学习，我们可以有效的学习这个顺序，来提升增强学习的效率。</p>
<p>我们今天所面临的学习问题可能是这样的一个情况：训练数据和测试数据来自不同的传感器或者信息域。这就是domain generalization要解决的问题。因为训练数据和测试数据来自不同的域，我们就需要找寻一些特征：这些特征在训练数据上和测试数据上，对于完成我们的规定任务来说都是有效的。</p>
<p>人可以很轻松的做到这一点：我儿子3岁的时候，我给他看过长颈鹿的卡通画片。当我带他去动物园的时候，他可能很轻松的认出真正的长颈鹿。可是在这之前，他从来没有见过实际场景中的长颈鹿。我们当然希望计算机也具备类似的能力。这里我们利用GAN网络（对抗生成网络）能够有效地学习这样的不变特征。</p>
<p>我们提出了一个端到端的条件对抗域自适应深度学习模型来学习域不变的特征，该模型同时衡量分布P(Y)和条件概率分布P(X|Y)的不变性。该网络框架包括了四个部分。第一部分AlexNet用来学习域不变的特征。第二部分是图像分类网络，用来保证学习的特征具有良好的类别区分性。</p>
<p>特征的域不变性质利用类别先验归一化域分类网络和类别条件域分类网络保证。其中类别先验归一化域分类网络用来匹配不同域的类别先验归一化分布，该网络的主要目的是消除不同域之间的变化。其次，类别条件域分类网络用来保证对于每一类的分布匹配。这样就能够保证不同域的联合概率分布是匹配的。在不同标准数据集上得到的实验结果证明了我们方法的有效性，并且要比现有方法有显著的提高。</p>
<p>最近大家开始关注学习的可解释性。我们用GAN网络可以学到特征来生成我们需要的数据。可是这些特征的含义是什么？我们并不清楚。</p>
<p>通过模仿人类理解世界的方式，我们希望计算机能够从这个复杂的世界中学习到抽象的概念，并根据这些概念创造新的东西。因此，我们需要计算机能够从真实世界图像中提取到可分解的特征，例如照片中人物的身份，拍摄角度，光照条件等等。这个就是tag disentanglement。有了可分解的特征，我们也能很好的解释我们学习到的特征到底是什么物理含义。</p>
<p>我们提出了一个新的框架（TD-GAN），用于从单个输入图像中提取可分解的特征，并通过调整所学特征来重新渲染图像。从某种程度上说，TD-GAN提供了一个可以理解现实世界中图像的深度学习框架。</p>
<p>网络所学习到的可分解的特征，实际上对应于图像中所描述主体的不同属性。与人类理解世界的方式相似，学习可分解的特征有助于机器解释并重构现实世界的图像。因此，TD-GAN能够根据用户指定的信息合成高质量的输出图像。</p>
<p>TD-GAN可应用于（1）数据增强，即通过合成新的图像以用于其他深度学习算法的训练与测试，（2）生成给定对象连续姿态的图像，以用于三维模型重建，以及（3）通过解析，概括来增强现有创作，并创造充满想象力的新绘画。</p>
<h2 id="多视角数据增强"><a href="#多视角数据增强" class="headerlink" title="多视角数据增强"></a><strong>多视角数据增强</strong></h2><p>我们目前做的多视角图片数据增强和TD-GAN又有一些不同。TD-GAN仅仅是在chairs这个dataset上产生了很好的效果，不过，试想，当一个物体较为复杂的时候，不可能根据一张图片生成这么完美的图像，那我们怎样产生多视角图像呢？</p>
<p>这恰恰是我们正在研究的内容，我们在探究一种让网络学会融合各视角的图像，如何使网络将各视角的图像组合起来，在“大脑”中构思出这个物体的“3d模型”。这其实是多视角学习，多模态学习很关键的一步。</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://lizekang.github.io/2018/11/19/hello-world/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zekang Li">
      <meta itemprop="description" content="Stay hungry, stay foolish.">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zekang Li's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/19/hello-world/" itemprop="url">
                  Hello World
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-11-19 13:24:36" itemprop="dateCreated datePublished" datetime="2018-11-19T13:24:36+08:00">2018-11-19</time>
            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

          
        
      
    </div>

    

    
    
    

    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://lizekang.github.io/2017/11/21/1/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zekang Li">
      <meta itemprop="description" content="Stay hungry, stay foolish.">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zekang Li's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/11/21/1/" itemprop="url">
                  boosting详解
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-11-21 15:30:00" itemprop="dateCreated datePublished" datetime="2017-11-21T15:30:00+08:00">2017-11-21</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-11-19 15:34:14" itemprop="dateModified" datetime="2018-11-19T15:34:14+08:00">2018-11-19</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p> Table of Contents Boosting算法简介PACAdaboostGDBTXGBoostLightGBMReference</p>
<p>Boosting算法简介</p>
<p>李泽康 2017.10.21 AI Lab</p>
<p>PAC</p>
<ul>
<li>Probably approximately correct（概率近似正确）</li>
<li>Strongly learnable（强可学习）<ul>
<li>Exist an algorithm that requires error can be driven arbitrarily close to 0.</li>
</ul>
</li>
<li>Weakly learnable（弱可学习）<ul>
<li>Exist an algorithm that only requires the hypothesis that does better than random guessing.</li>
</ul>
</li>
<li>一个概念是强可学习的充分必要条件是这个概念是弱可学习的。</li>
</ul>
<p>Adaboost</p>
<ul>
<li>Adaboost从训练数据中学习一系列弱分类器，并将这些弱分类器线性组合成一个强分类器。</li>
<li>它是一个加法模型:<br> f(x)=\sum <em>{m=1}^{M}\alpha</em>{m} G_{m}(x)<br>\alpha <em>{m} ：分类器的系数， G</em>{m}(x) :不同的弱分类器 </li>
<li>损失函数为指数函数：<br> (\alpha <em>{m}, G</em>{m}(x)) = \arg \min_{\alpha, G} \sum_{i=1}^{N}\overline w_{mi}exp[-y_{i}\alpha G(x_{i})]<br>其中  \overline w_{mi} = exp[-y_{i}f_{m-1}(x_{i})]   </li>
<li>Adaboost 算法原理(以二分类为例)<br>输入：  (x_{i}, y_{i}), y={-1, +1}<ol>
<li>初始化训练数据的权值分布： D_{1} = (w_{11}, …,w_{1i},…,w_{1N}) , w_{1i} = \frac{1}{N}, i=1,2,…,N</li>
<li>对m=1, 2, …, M :<ol>
<li>使用权值分布为D_{m} 训练得到弱分类器：G_{m}(x)</li>
<li>计算误差率：e_{m} = \sum <em>{i=1}^{N}w</em>{mi}I(G_{m}(x_{i}) \neq y_{i}) </li>
<li>计算分类器系数\alpha _{m} : \alpha <em>{m} = \frac{1}{2}log\frac{1-e</em>{m}}{e_m} </li>
<li>更新权值分布：<br>D_{m+1} = (w_{m+1,1},…,w_{m+1,i}, … , w_{m+1,N})<br>w_{m+1, i} = \frac{w_{mi}}{Z_{m}}exp(-\alpha_{m}y_{i}G_{m}(x_{i}))<br>Z_{m} = \sum_{i=1}^{N}w_{mi}exp(-\alpha_{m}y_{i}G_{m}(x_{i}))<br>其中，规范化因子Z_{m} 使D_{m+1} 成为一个概率分布</li>
</ol>
</li>
<li>构建分类器的线性组合: f(x)=\sum <em>{m=1}^{M}\alpha</em>{m} G_{m}(x) 得到最终分类器G_{m}(x) = sign(f(x)) </li>
</ol>
</li>
<li>一些分析<ol>
<li>Adaboost的正则化（防止过拟合）：定义learning_rate l ,前面有：f_{m}(x) = f_{m-1}(x) + \alpha_mG_{m}(x)<br>加上正则化项有：f_{m}(x) = f_{m-1}(x) + l\alpha_mG_{m}(x) </li>
<li>\alpha_{m}随e_{m} 减小而增大，分类错误率越小的基本分类器在最终分类器中的作用越大</li>
<li>adaboost不改变数据，只是改变数据的权值</li>
<li>Adaboost的训练误差界：<br>\frac{1}{N}\sum_{i=1}^{N}I(G_(x_{i}) \neq y_{i}) \leq \frac{1}{N}\sum_{i}exp(-y_{i}f(x_{i})) = \prod_{m}Z_{m} \leq exp(-2\sum_{m=1}^{M}\gamma_{m}^{2}), \gamma_{m} = \frac{1}{2} - e_{m}<br>So, adaboost训练误差以指数速率下降！</li>
<li>Adaboost使用比较广泛的弱学习器是决策树和神经网络。</li>
<li>优势：分类精度比较高，比较灵活可以使用各种回归、分类模型作为弱学习器，不容易发生过拟合<br>缺点：对异常数据比较敏感，可能对异常数据赋较大权值。</li>
</ol>
</li>
</ul>
<p>GDBT</p>
<ul>
<li>Gradient Decent Boosting Tree </li>
<li>Gradient Boosting 就是在函数空间的梯度下降</li>
<li>是一个加法模型：<br>F(x;w)=\sum_{m=0}^{M}a_{m}h_{m}(x;w_{m})=\sum_{m=0}^{M}f_{m}(x;w_{m})<br>x ：输入样本，h_{m}  :分类回归树，w：回归树的参数，\alpha_{m}  :每棵树权重</li>
<li>GDBT算法原理<br>输入：(x_{i}, y_{i}), M, L <ol>
<li>初始化f_{0}  </li>
<li>对m = 1,2,…,M :<ol>
<li>响应：\widetilde {y}<em>{i} = -[\frac{\partial L(y</em>{i}, F(x_{i}))}{\partial F(x_{i})}]<em>{F(x)=F</em>{m-1}(x)}, i=1,…,N   </li>
<li>学习第m棵树：w_{m} = \arg \min_{w}\sum_{i=1}^{N}(\widetilde y_{i}-h_{m}(x_{i}; w_{m-1}))^{2}  </li>
<li>line search 寻找步长：\rho_{m} = \arg \min_{\rho} \sum_{i=1}^{N}L(y_{i}, F_{m-1}(x_{i}) + \rho h(x_{i};w_{m}))    </li>
<li>令f_{m} = \rho_{m}h_{m} 则F_{m} = F_{m-1} + f_{m}  </li>
</ol>
</li>
</ol>
</li>
<li>一些分析<ol>
<li>GDBT就是使用决策树作为基分类器的boosting方法。与Adaboost不同的是GDBT是一个不断拟合残差并直接叠加到F上的过程，残差不断减小，Loss不断减小。</li>
<li>在GDBT里，F是泛函空间，f是函数，组合时直接叠加。而Adaboost中f是有权重的，在GDBT中权重信息被吸收到决策树的叶子节点里了。</li>
<li>初始化的时候<ul>
<li>随机</li>
<li>用训练样本的充分统计量初始化</li>
<li>用其他模型的预测值初始化，例：GDBT在搜索引擎排序中的应用 它使用了RF的输出作为GDBT的初始化，取得了不错的效果。</li>
</ul>
</li>
<li>使用GDBT生成新特征，Practical Lessons from Predicting Clicks on Ads at Facebook, 2014.  </li>
</ol>
</li>
</ul>
<p>XGBoost</p>
<ul>
<li>GDBT是函数空间的梯度下降，XGBoost是函数空间的牛顿法</li>
<li>相比于GDBT，XGBoost多了正则化项，目标函数变为：\sum_{L}L(\hat y_{i}; y_{i}) + \sum_{k}\Omega(f_{k})<br>XGBoost采用的正则化项：\Omega(f) = \gamma T + \frac{1}{2}\lambda||w||^{2} , 其中，T：叶子节点数，w：叶节点分数</li>
<li>误差函数的二阶泰勒展开：<ol>
<li>在第t次迭代后：\hat y_{i}^{(t)} = \hat y_{i}^{(t-1)} + f_{t}(x_{i}) </li>
<li>此时损失函数可以写为：L(\hat y_{i}^{(t-1)} + f_{t}(x_{i}), y_{i}) ，需要学习的只有f_{t} </li>
<li>在\hat y_{i}^{(t-1)} 处将损失函数进行二阶泰勒展开：L(\hat y_{i}^{(t-1)}, y_{i}) + g_{i}f_{t}(x_{i}) + \frac{1}{2}h_{i}f_{t}^{2}(x_{i})<br>其中，g_{i} = \partial_{\hat y^{(t-1)}}L(\hat y^{(t-1)},y_{i})   , h_{i} = \partial^{2}<em>{\hat y^{(t-1)}}L(\hat y^{(t-1)}, y</em>{i}) </li>
<li>显然，L(\hat y_{i}^{(t-1)}, y_{i}) 为常数，可以消掉，目标函数：\widetilde {\mathcal {L}}^{(t)} = \sum_{i=1}^{N}[ g_{i}f_{t}(x_{i}) + \frac{1}{2}h_{i}f_{t}^{2}(x_{i})] + \Omega(f_{t})   </li>
<li>\widetilde {\mathcal {L}}^{(t)} = \sum_{i=1}^{N}[ g_{i}f_{t}(x_{i}) + \frac{1}{2}h_{i}f_{t}^{2}(x_{i})] + \gamma T + \frac{1}{2}||w||^{2} = \sum_{i=1}^{N}[g_{i}w_{q_(x_{i})} + \frac{1}{2}h_{i}w_{q(x_{i})}] + \gamma T + \frac{1}{2}\lambda \sum <em>{j=1}^{T} w</em>{j}^{2}  </li>
<li>这个式子感觉挺复杂，现在我们要把他们统一起来，w_{q(x_{i})} 表示回归树对每个样本的预测值，w_{j} 表示每个叶子节点的分数，q(x_{i}) 表示将样本分到某个叶子节点上。我们可以设集合I_{j} = {i|q(x_{i}) = j} ，此时：<br>\widetilde {\mathcal {L}}^{(t)} = \sum_{j=1}^{T}[\sum_{i\in I_{j}}g_{i}w_{j} + \frac{1}{2} (\sum_{i\in I_{j}}h_{i} + \lambda)w_{j}^{2}] + \gamma T = \sum <em>{j=1}^{T}[G</em>{j}w_{j} + \frac{1}{2} (H_{j} + \lambda )w_{j}^{2}] + \gamma T   </li>
<li>如何来使损失函数最小化：假定树的结构确定了，那么我们需要调整的只是w_{j} ，当\widetilde {\mathcal {L}}^{(t)} 对w_{j} 导数为0时，取到极小，此时可以得到最优预测分数和最小损失：<br>w_{j}^{<em>} = - \frac{G_{j}}{H_{j} + \lambda} , \widetilde {\mathcal {L}}^{</em>} = -\frac{1}{2}\sum_{j=1}^{T}\frac{G_{j}^{2}}{H_{j} + \lambda } + \gamma T </li>
<li>So， 怎么去确定树的结构呢？<ol>
<li>暴力解所有树结构（np难啊）</li>
<li>贪心，每次分裂一个节点，计算增益：Gain = \frac{G_{L}^{2}}{H_{L} + \lambda} + \frac{G_{R}^{2}}{H_{R} + \lambda} - \frac{(G_{L} + G_{R})^{2}}{(H_{L} + H_{R}) + \lambda} -\gamma <ul>
<li>exact greedy</li>
<li>Weighted Quantile Sketch</li>
</ul>
</li>
</ol>
</li>
</ol>
</li>
<li>并行</li>
<li>优势：<ol>
<li>加入了正则化</li>
<li>使用了二阶导信息</li>
<li>列抽样来防止过拟合</li>
<li>Weighted Quantile Sketch</li>
<li>样本数据预先排序，存储为block，利于并行</li>
<li>可以对缺失值自动处理</li>
</ol>
</li>
<li>调参<br><a href="https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/" target="_blank" rel="noopener">https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/</a></li>
</ul>
<p>LightGBM</p>
<p>一个基于决策树算法的分布式梯度提升框架，<a href="https://github.com/Microsoft/LightGBM" target="_blank" rel="noopener">https://github.com/Microsoft/LightGBM</a></p>
<ul>
<li>与xgboost的速度比较<br>  Data         xgboost      xgboost_hist    LightGBM<br>  Higgs        3794.34 s    551.898 s       238.505513 s<br>  Yahoo LTR    674.322 s    265.302 s       150.18644 s<br>  MS LTR       1251.27 s    385.201 s       215.320316 s<br>  Expo         1607.35 s    588.253 s       138.504179 s<br>  Allstate     2867.22 s    1355.71 s       348.084475 s</li>
<li>内存占用比较：<br>  Data         xgboost    xgboost_hist    LightGBM<br>  Higgs        4.853GB    3.784GB         0.868GB<br>  Yahoo LTR    1.907GB    1.468GB         0.831GB<br>  MS LTR       5.469GB    3.654GB         0.886GB<br>  Expo         1.553GB    1.393GB         0.543GB<br>  Allstate     6.237GB    4.990GB         1.027GB </li>
<li>准确率比较：<pre><code>Data       Metric    xgboost     xgboost_hist    LightGBM
Higgs      AUC       0.839593    0.845605        0.845154
</code></pre>  Yahoo LTR    NDCG1     0.719748    0.720223        0.732466<br>   MS LTR      NDCG1     0.483956    0.488649        0.524255<pre><code>Expo       AUC       0.756713    0.777777        0.777543
</code></pre></li>
<li>两者区别：<ol>
<li>切分算法：<ol>
<li>xgboost基于预排序（pre-sorted），对所有特征进行预排序，在寻找分割点时代价为O(#data)。很精确，但空间，时间，cache优化不友好。</li>
<li>LightGBM使用了Histogram算法,它主要是把连续的浮点值离散化为k个整数，构造一个宽度为#bins（k）的直方图。根据这些离散值寻找最优分割。内存消耗大大降低，这样不需要存储预排序的结果，而且可以只保存特征离散后的值，这个值一般用8位整型存就够了，而在预排序算法中，需要使用32位分别储存index和feature value。内存消耗降低到1/8。时间复杂度从O(#data <em> #feature)变为O(#bins </em> #feature)。很好的利用了弱模型集成的思想。</li>
</ol>
</li>
</ol>
</li>
</ul>
<ol start="2">
<li>决策树生长策略：<ol>
<li>xgboost使用level-wise（容易多线程优化，控制模型复杂度，不容易过拟合，但比较低效）</li>
<li>LightGBM使用带深度限制的leaf-wise</li>
</ol>
</li>
<li>LightGBM 的直方图差加速优化，提升一倍速度。</li>
<li>高效并行<ol>
<li>原始<br>特征并行    的主要思想是在不同机器在不同的特征集合上分别寻找最优的分割点，然后在机器间同步最优的分割点。<br>数据并行则是让不同的机器先在本地构造直方图，然后进行全局的合并，最后在合并的直方图上面寻找最优分割点。</li>
<li>LightGBM针对这两种并行方法都做了优化<br>在特征并行算法中，通过在本地保存全部数据避免对数据切分结果的通信；<br>在数据并行中使用分散规约(Reduce scatter)把直方图合并的任务分摊到不同的机器，降低通信和计算，并利用直方图做差，进一步减少了一半的通信量。基于投票的数据并行(Parallel Voting)则进一步优化数据并行中的通信代价，使通信代价变成常数级别。</li>
</ol>
</li>
<li>LightGBM是第一个直接支持类别特征的GBDT工具</li>
</ol>
<p>Reference</p>
<ul>
<li>Greedy function approximation a gradient boosting machine. J.H.Friedman(1999)  </li>
<li>XGBoost: A Scalable Tree Boosting System. T. Chen, C. Guestrin (2016) </li>
<li>CS260 : Lecture 13: Weak vs. Strong Learning and the Adaboost Algorithm </li>
<li>《统计学习方法》李航著</li>
<li>LightGBM(github)   </li>
<li><a href="http://www.msra.cn/zh-cn/news/features/lightgbm-20170105" target="_blank" rel="noopener">http://www.msra.cn/zh-cn/news/features/lightgbm-20170105</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.gif" alt="Zekang Li">
            
              <p class="site-author-name" itemprop="name">Zekang Li</p>
              <p class="site-description motion-element" itemprop="description">Stay hungry, stay foolish.</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">4</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">2</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">7</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/lizekang" target="_blank" title="GitHub"><i class="fa fa-fw fa-globe"></i>GitHub</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:zekangli97@gmail.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-globe"></i>E-Mail</a>
                  
                </span>
              
            </div>
          

          
          

          
          

          
            
          
          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright"> &copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zekang Li</span>

  

  
</div>




  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a class="theme-link" target="_blank" href="https://theme-next.org">NexT.Gemini</a> v6.5.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.5.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.5.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.5.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.5.0"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.5.0"></script>



  



  










  





  

  

  

  

  
  

  
  
    
      
        
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  

  

  

  

  

  

</body>
</html>
